import tensorflow as tf
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
import gc

from ToonNet import ToonNet, ToonResNet, ToonResNet1x1Outter
from datasets.TinyImagenet import TinyImagenet
from utils import montage

batch_size = 250
nb_epoch = 5

with tf.device('/gpu:1'):

    # Get the data-set object
    data = TinyImagenet()

    # Load the net
    net, _ = ToonResNet(input_shape=data.get_dims(), batch_size=batch_size)

    datagen = ImageDataGenerator(
        featurewise_center=False,  # set input mean to 0 over the dataset
        samplewise_center=False,  # set each sample mean to 0
        featurewise_std_normalization=False,  # divide inputs by std of the dataset
        samplewise_std_normalization=False,  # divide each input by its std
        zca_whitening=False,  # apply ZCA whitening
        rotation_range=False,  # randomly rotate images in the range (degrees, 0 to 180)
        width_shift_range=False,  # randomly shift images horizontally (fraction of total width)
        height_shift_range=False,  # randomly shift images vertically (fraction of total height)
        horizontal_flip=False,  # randomly flip images
        vertical_flip=False)  # randomly flip images

    # compute quantities required for featurewise normalization
    # (std, mean, and principal components if ZCA whitening is applied)
    X_sample = data.get_sample(5000)
    datagen.fit(X_sample)

    for e in range(nb_epoch):
        print("Epoch {} / {}".format(e+1, nb_epoch))
        for X_train, Y_train, X_test, Y_test in data.generator():
            # fit the model on the batches generated by datagen.flow()
            net.fit_generator(datagen.flow(X_train, Y_train - X_train,
                                           batch_size=batch_size),
                              samples_per_epoch=X_train.shape[0],
                              nb_epoch=1,
                              validation_data=(X_test, Y_test - X_test))
            gc.collect()

    decoded_imgs = net.predict(X_test, batch_size=batch_size) + X_test
    decoded_imgs = np.clip(decoded_imgs, 0.0, 1.0)

montage(X_test[:100, :, :], 'ToonResNet-X')
montage(decoded_imgs[:100, :, :], 'ToonResNet-Out')
montage(Y_test[:100, :, :], 'ToonResNet-Y')
