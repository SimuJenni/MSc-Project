import matplotlib.pyplot as plt
from keras.callbacks import TensorBoard
from keras.layers import Input, Convolution2D, BatchNormalization, Deconvolution2D, Activation
from keras.models import Model
from keras.preprocessing.image import ImageDataGenerator

from datasets.TinyImagenet import TinyImagenet

batch_size = 250
nb_epoch = 5

# Get the data-set object
data = TinyImagenet()

# Image dimensions
img_rows, img_cols, img_channels = data.get_dims()

input_img = Input(shape=(img_rows, img_cols, img_channels))
x = Convolution2D(128, 3, 3, border_mode='valid', subsample=(2, 2))(input_img)
x = BatchNormalization(axis=3)(x)
x = Activation('relu')(x)
x = Convolution2D(256, 3, 3, border_mode='valid', subsample=(2, 2))(x)
x = BatchNormalization(axis=3)(x)
x = Activation('relu')(x)
x = Convolution2D(512, 3, 3, border_mode='valid', subsample=(2, 2))(x)
x = BatchNormalization(axis=3)(x)
encoded = Activation('relu')(x)

x = Deconvolution2D(256, 3, 3, output_shape=(batch_size, 15, 15, 256), border_mode='valid', subsample=(2, 2))(
    encoded)
x = BatchNormalization(axis=3)(x)
x = Activation('relu')(x)
x = Deconvolution2D(128, 3, 3, output_shape=(batch_size, 31, 31, 128), border_mode='valid', subsample=(2, 2))(x)
x = BatchNormalization(axis=3)(x)
x = Activation('relu')(x)
x = Deconvolution2D(64, 3, 3, output_shape=(batch_size, 63, 63, 64), border_mode='valid', subsample=(2, 2))(x)
x = BatchNormalization(axis=3)(x)
x = Activation('relu')(x)
decoded = Deconvolution2D(3, 2, 2, output_shape=(batch_size, 64, 64, 3), activation='tanh', border_mode='valid',
                          subsample=(1, 1))(x)

autoencoder = Model(input_img, decoded)
autoencoder.summary()
autoencoder.compile(optimizer='adam', loss='mse')

datagen = ImageDataGenerator(
    featurewise_center=True,  # set input mean to 0 over the dataset
    samplewise_center=False,  # set each sample mean to 0
    featurewise_std_normalization=True,  # divide inputs by std of the dataset
    samplewise_std_normalization=False,  # divide each input by its std
    zca_whitening=False,  # apply ZCA whitening
    rotation_range=False,  # randomly rotate images in the range (degrees, 0 to 180)
    width_shift_range=False,  # randomly shift images horizontally (fraction of total width)
    height_shift_range=False,  # randomly shift images vertically (fraction of total height)
    horizontal_flip=False,  # randomly flip images
    vertical_flip=False)  # randomly flip images

# compute quantities required for featurewise normalization
# (std, mean, and principal components if ZCA whitening is applied)
X_sample = data.get_sample(3000)
datagen.fit(X_sample)

for e in range(nb_epoch):
    print("epoch %d" % e)
    for X_train, Y_train, X_test, Y_test in data.generator():
        # fit the model on the batches generated by datagen.flow()
        autoencoder.fit_generator(datagen.flow(X_train, Y_train,
                                               batch_size=batch_size),
                                  samples_per_epoch=X_train.shape[0],
                                  nb_epoch=1,
                                  validation_data=(X_test, Y_test),
                                  callbacks=[TensorBoard(log_dir='./logs')])

decoded_imgs = autoencoder.predict(X_test, batch_size=batch_size)

n = 15
plt.figure(figsize=(20, 6))
for i in range(n):
    # display original input
    ax = plt.subplot(3, n, i + 1)
    plt.imshow(X_test[i].reshape(img_rows, img_cols, img_channels))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display reconstruction
    ax = plt.subplot(3, n, i + n + 1)
    plt.imshow(decoded_imgs[i].reshape(img_rows, img_cols, img_channels))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)

    # display ground truth
    ax = plt.subplot(3, n, i + n + n + 1)
    plt.imshow(decoded_imgs[i].reshape(img_rows, img_cols, img_channels))
    plt.gray()
    ax.get_xaxis().set_visible(False)
    ax.get_yaxis().set_visible(False)
plt.show()
plt.savefig('test.pdf')
